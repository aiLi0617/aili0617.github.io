---
layout:     post
title:      Redis
subtitle:   个人整理的文档
date:       2021-06-16
author:     墙纸
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
- Redis
---
## Redis是什么？

![img](https://gss3.bdstatic.com/84oSdTum2Q5BphGlnYG/timg?wapp&quality=80&size=b150_150&subsize=20480&cut_x=0&cut_w=0&cut_y=0&cut_h=0&sec=1369815402&srctrace&di=0777696379a4df1ea720f24c73e9c0ef&wh_rate=null&src=http%3A%2F%2Fimgsrc.baidu.com%2Fforum%2Fpic%2Fitem%2F7af40ad162d9f2d390ed4c4babec8a136227cc92.jpg)

​        Redis（Remote Dictionary Server )，即远程字典服务，是一个开源的使用ANSI [C语言](https://baike.baidu.com/item/C%E8%AF%AD%E8%A8%80)编写、支持网络、可基于内存亦可持久化的日志型、Key-Value[数据库](https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E5%BA%93/103728)，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由[Pivotal](https://baike.baidu.com/item/Pivotal)赞助。

## 面试题：什么是redis?

redis是一个高性能的key-value数据库，它是完全开源免费的，而且redis是一个NOSQL类型数据库，是为了解决高并发、高扩展等一系列的问题而产生的数据库解决方案，是一个非关系型的数据库

# NoSQL是什么？

- NoSQL(NoSQL = Not Only SQL)，意即“不仅仅是SQL”，是一项全新的数据库理念，泛指非关系型的数据库。
- 随着互联网web2.0网站的兴起，传统的关系数据库在应付web2.0网站，特别是超大规模和高并发的SNS类型的web2.0纯动态网站已经显得力不从心，暴露了很多难以克服的问题，而非关系型的数据库则由于其本身的特点得到了非常迅速的发展。NoSQL数据库的产生就是为了解决大规模数据集合多重数据种类带来的挑战，尤其是大数据应用难题。

总结：

​	关系型数据库与NoSQL数据库并非对立而是互补的关系，即通常情况下使用关系型数据库，在适合使用NoSQL的时候使用NoSQL数据库，让NoSQL数据库对关系型数据库的不足进行弥补。一般会将数据存储在关系型数据库中，在nosql数据库中备份存储关系型数据库的数据

## Redis能干什么？

缓存，毫无疑问这是Redis当今最为人熟知的使用场景。再提升服务器性能方面非常有效；

计算器/限速器，利用Redis中原子性的自增操作，我们可以统计类似用户点赞数、用户访问数等，这类操作如果用MySQL，频繁的读写会带来相当大的压力；限速器比较典型的使用场景是限制某个用户访问某个API的频率，常用的有抢购时，防止用户疯狂点击带来不必要的压力；

简单消息队列，除了Redis自身的发布/订阅模式，我们也可以利用List来实现一个队列机制，比如：到货通知、邮件发送之类的需求，不需要高可靠，但是会带来非常大的DB压力，完全可以用List来完成异步解耦；

Session共享，默认Session是保存在服务器的文件中，即当前服务器，如果是集群服务，同一个用户过来可能落在不同机器上，这就会导致用户频繁登陆；采用Redis保存Session后，无论用户落在那台机器上都能够获取到对应的Session信息。

1，缓存（最常用）  **面试**
2，消息队列，
比如支付3，活动排行榜或计数
4，发布，订阅消息（消息通知）
5，商品列表，评论列表等

## 面试题：redis相比memcached有哪些优势？

memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型**4.2** redis的速度比memcached快很多 (3) redis可以持久化其数据

## 面试题：Memcache与Redis的区别都有哪些？

**5.1** 存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。Redis有部份存在硬盘上，这样能保证数据的持久性。

**5.2** 数据支持类型 Memcache对数据类型支持相对简单。Redis有复杂的数据类型。

**5.3** 使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。

# Redis有哪些优缺点★

## 优点

读写性能优异， Redis能读的速度是110000次/s，写的速度是81000次/s。
支持数据持久化，支持AOF和RDB两种持久化方式。
数据结构丰富，除了支持string类型的value外还支持hash、set、zset、list等数据结构。
支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。

## 缺点

数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。

**Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。**

**主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。**
**Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。**

## **面试题：Reids的特点**

Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。

Redis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。

Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。

## 面试题：使用redis有哪些好处？

速度快，因为数据存在内存中

支持丰富数据类型，支持string，list，set，sorted set，hash



# ★此处面试题：redis是单线程的为什么速度还这么快？ 

**1.redis是基于内存的，内存的读写速度非常快；**
**2.redis是单线程的，省去了很多上下文切换线程的时间；**
**3.redis使用多路复用技术，可以处理并发的连接；**

简单解释下第二条：上下文切换就是cpu在多线程之间进行轮流执行（抢占cpu资源），而redis单线程的，因此避免了繁琐的多线程上下文切换。

重点解释下多路复用：
多路-指的是多个socket连接，复用-指的是复用一个线程。
目前，多路复用主要有三种技术：select，poll，epoll。它们出现的顺序是按后的，越排后的技术改正了之前技术的缺点。epoll是最新的也是目前最好的多路复用技术。

## redis 采用网络IO多路复用技术来保证在多连接的时候， 系统的高吞吐量。

举个例子：一个酒吧服务员，前面有很多醉汉，epoll这种方式相当于一个醉汉吼了一声要酒，服务员听见之后就去给他倒酒，而在这些醉汉没有要求的时候可以玩玩手机等。但是select和poll技术是这样的场景：服务员轮流着问各个醉汉要不要倒酒，没有空闲的时间。io多路复用的意思就是做个醉汉公用一个服务员。

- select：
  1.会修改传入的参数，对于多个调用的函数来说非常不友好；
  2.要是sock（io流出现了数据），select只能轮询这去找数据，对于大量的sock来说开销很大；
  3.不是线程安全的，很恐怖；
  4.只能监视1024个连接；
- poll：
  1.还不是线程安全的...
  2.去掉了1024个连接的限制；
  3.不修改传入的参数了；
- epoll：
  1.线程安全了；
  2.epoll不仅能告诉你sock有数据，还能告诉你哪个sock有数据，不用轮询了；
  3.however，只支持linux系统；

# ★redis为什么是单线程，多路复用

## redis为什么是单线程

多线程：多线程的目的就是   最大限度利用cpu资源    

因为redis是基于内存操作的，内存读写非常快，cpu处理更快，会很大利用cpu资源，让redis更快的可能就是内存更大或者带宽更高，所以是单线程就很欧克。

## 多路复用

 	[数据通信系统](https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E7%B3%BB%E7%BB%9F/10953537)或计算机网络系统中，[传输媒体](https://baike.baidu.com/item/%E4%BC%A0%E8%BE%93%E5%AA%92%E4%BD%93/4245209)的带宽或[容量](https://baike.baidu.com/item/%E5%AE%B9%E9%87%8F/6067331)往往会大于传输单一信号的需求，为了有效地利用[通信线路](https://baike.baidu.com/item/%E9%80%9A%E4%BF%A1%E7%BA%BF%E8%B7%AF),希望一个[信道](https://baike.baidu.com/item/%E4%BF%A1%E9%81%93)同时传输多路信号，这就是所谓的[多路复用技术](https://baike.baidu.com/item/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E6%8A%80%E6%9C%AF/5785640)(Multiplexing)。采用多路复用技术能把多个信号组合起来在一条[物理信道](https://baike.baidu.com/item/%E7%89%A9%E7%90%86%E4%BF%A1%E9%81%93/3288982)上进行传输，在远距离传输时可大大节省[电缆](https://baike.baidu.com/item/%E7%94%B5%E7%BC%86/5942260)的安装和维护[费用](https://baike.baidu.com/item/%E8%B4%B9%E7%94%A8/9277833)。[频分多路复用](https://baike.baidu.com/item/%E9%A2%91%E5%88%86%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/10266827)FDM (Frequency Division Multiplexing)和[时分多路复用](https://baike.baidu.com/item/%E6%97%B6%E5%88%86%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/7831037)TDM (Time Division Multiplexing)是两种最常用的多路复用技术。



字面意思，多个路段，复用一条线

# 安装

可以在winows安装。也可以在Linux安装，这里只讲在**Linux**安装

下载：http://download.redis.io/releases/

## 1.先把安装包准备到linux下

![1622534555295](Redis_index.assets/1622534555295.png)

## 2.把压缩包解压

![1622534662136](Redis_index.assets/1622534662136.png)



### 移动到  mv redis-5.0.12 /usr/local



![1623239854368](Redis_index.assets/1623239854368.png)

## 3.安装c环境

![1622534788963](Redis_index.assets/1622534788963.png)

![1622534838527](Redis_index.assets/1622534838527.png)

![1623239935823](Redis_index.assets/1623239935823.png)

(★)更新一下gcc

```java
yum -y install centos-release-scl

yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils

#这句是临时的
scl enable devtoolset-9 bash

#修改环境变量
echo "source /opt/rh/devtoolset-9/enable" >> /etc/profile

gcc -v
```



## 4.在redis下src安装redis

![1623240298611](Redis_index.assets/1623240298611.png)

为了方便管理，将Redis文件中的conf配置文件和常用命令移动到统一文件中



![1623240376425](Redis_index.assets/1623240376425.png)

## 5.拷贝一份配置文件

```bas

cp redis.conf  z_config/

cp  mkreleasehdr.sh redis-benchmark redis-check-aof redis-cli redis-server ../bin

```



​		修改一下配置文件

​		![1622536488710](Redis_index.assets/1622536488710.png)

## 6.启动redis服务

![1622536639359](Redis_index.assets/1622536639359.png)

## 7.测试连接

![1622536762922](Redis_index.assets/1622536762922.png)



# Redis的基础

reids默认有16个数据库

![1622537370705](Redis_index.assets/1622537370705.png)

可以用select 切换数据库

还可以查看当前数据库的大小DBSIZE

![1622537480934](Redis_index.assets/1622537480934.png)



查看数据库所有的key

![1622537554834](Redis_index.assets/1622537554834.png)



清空当前库flushdb

![1622537578616](Redis_index.assets/1622537578616.png)

清除所有库flushall

![1622537602563](Redis_index.assets/1622537602563.png)

判断某个键是否存在exists

![1622539256075](Redis_index.assets/1622539256075.png)

移动哪个键到几号数据库 move name 1

![1622539309220](Redis_index.assets/1622539309220.png)

**★自动过期expire**

ttl查看键的自动过期时间 



![1622539403114](Redis_index.assets/1622539403114.png)

查看key的类型 type

![1622539466050](Redis_index.assets/1622539466050.png)



# Redis的五大数据类型

## 1.String

**常用命令** ：set/get/decr/incr/mget等；

**应用场景** ：String是最常用的一种数据类型，普通的key/value存储都可以归为此类；

实现方式：String在redis内部存储默认就是一个字符串，被redisObject所引用，当遇到incr、decr等操作时会转成数值型进行计算，此时redisObject的encoding字段为int

-----------------------------------------------------------------------------------------------------------------------------------------------------------

APPEND 键名 值  给key的值追加值，如果当前key不存在就相当于set了一个key

STRLEN 键 查看该键的值的长度

set views 0 键，0代表默认值

incr key key值加一，自增，计数器 i++

decr key key值减一,i--

INCRBY key 10 步长为10 ，i+=10

DECRBY ...

GETRANGE key 开始索引 结束索引  截取字符串

GETRANGE key 0 -1 获取全部字符串

SETRANGE  key 开始索引 要替换的值  相当于replace

setex (ser with expire) 设置过期时间，后面跟着提示呢~

setnx (set if not exist) 不存在则set成功返回1，存在返回0

mset 同时设置多个值

mget 同时获取多个值

msetnx 原子性操作，要么一起成功，要么一起失败



**对象**

set user:1 {name:aaa,age:18} 设置一个user:1 对象，值为json字符串保存的以一个对象

user:{id}:{field}，这种设计在redis中是完全ok的，eg：mset user:1:name aaa user:1:age 18



getset 先get后set，如果不存在值，返回null，如果存在，就获取原来的值，并设置新的值

Spring类似的使用场景：value除了是字符串还可以是数字

- 计数器
- 统计多单位的数量 
- 粉丝数
- 对象缓存存储

## 2.List

**常用命令** ：lpush/rpush/lpop/rpop/lrange等；

**应用场景** ：Redis list的**应用场景** 非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表，粉丝列表等都可以用Redis的list结构来实现；

-----------------------------------------------------------------------------------------------------------------------------------------------------------

在redis中，可以把list玩成栈，队列，阻塞队列

所有的list命令都是以"l"开头的，redis不区分大小写

**push：**

```bash
127.0.0.1:6379> LPUSH list one #将一个值或者多个值，插入列表头部
(integer) 1
127.0.0.1:6379> LPUSH list two
(integer) 2
127.0.0.1:6379> LRANGE list 0 -1#获取list中的值
1) "two"
2) "one"
127.0.0.1:6379> LRANGE list 0 1#通过区间获取具体的值
1) "two"
2) "one"
127.0.0.1:6379> RPUSH list right#将一个值或者多个值，插入列表尾部，取值顺序，从左往右
(integer) 3
127.0.0.1:6379> LRANGE list 0 -1
1) "two"
2) "one"
3) "right"
127.0.0.1:6379> 
```

**pop：**

```bash
127.0.0.1:6379> LRANGE list 0 -1
1) "two"
2) "one"
3) "right"
127.0.0.1:6379> LPOP list#移除列表的第一个元素
"two"
127.0.0.1:6379> RPOP list#移除列表的最后一个元素
"right"
127.0.0.1:6379> LRANGE list 0 -1
1) "one"
127.0.0.1:6379> 
```

**index：**

```bash
127.0.0.1:6379> LINDEX list 1#通过下表获得list中的某个值
(nil)
127.0.0.1:6379> LINDEX list 0
"one"
127.0.0.1:6379> LPUSH list two
(integer) 2
127.0.0.1:6379> LPUSH list three
(integer) 3
127.0.0.1:6379> LLEN list#返回列表的长度
(integer) 3
###########################################################################
移除指定的值

127.0.0.1:6379> LPUSH list three
(integer) 4
127.0.0.1:6379> LRANGE list 0 -1
1) "three"
2) "three"
3) "two"
4) "one"
127.0.0.1:6379> LREM list 1 one#移除list集合中指定个数的value，精确匹配
(integer) 1
127.0.0.1:6379> LRANGE list 0 -1
1) "three"
2) "three"
3) "two"
127.0.0.1:6379> LREM list 2 three
(integer) 2
127.0.0.1:6379> LRANGE list 0 -1
1) "two"
127.0.0.1:6379> 
###########################################################################
trim 修剪

127.0.0.1:6379> RPUSH list "hello"
(integer) 1
127.0.0.1:6379> RPUSH list "hello1"
(integer) 2
127.0.0.1:6379> RPUSH list "hello2"
(integer) 3
127.0.0.1:6379> RPUSH list "hello3"
(integer) 4
127.0.0.1:6379> LTRIM list 1 2#通过下标截取指定的长度
OK
127.0.0.1:6379> LRANGE list 0 -1
1) "hello1"
2) "hello2"

###########################################################################
rpoplpush 移除列表的最后一个元素，并将它移动到新的列表中

127.0.0.1:6379> RPUSH list "hello"
(integer) 3
127.0.0.1:6379> RPOPLPUSH list mylist
"hello"
127.0.0.1:6379> LRANGE mylist 0 -1 
1) "hello"

###########################################################################
lset ，将列表中指定的值替换为另外一个值
127.0.0.1:6379> LSET mylist 0 ccc
OK
127.0.0.1:6379> LRANGE mylist 0 -1#如果不存在，报错，存在就更新
1) "ccc"

###########################################################################
linsert，将某一个具体的值插入到列表中某个元素的前面或者后面
127.0.0.1:6379> LINSERT mylist before "ccc" "hhh"
(integer) 2
127.0.0.1:6379> LRANGE mylist 0 -1
1) "hhh"
2) "ccc"
127.0.0.1:6379> LINSERT mylist after "ccc" "lll"
(integer) 3
127.0.0.1:6379> LRANGE mylist 0 -1
1) "hhh"
2) "ccc"
3) "lll"

```

实际上是一个链表，before node after，right，left都可以插入值

如果key不存在，创建新的链表，存在的话，新增内容

两边插入或者改动值，效率最高！中间元素效率低

消息排队，消息队列

## 3.set

**常用命令** ：sadd/spop/smembers/sunion等；

**应用场景** ：Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的；

-----------------------------------------------------------------------------------------------------------------------------------------------------------

集合，值不能重复

```bash
###########################################################################
127.0.0.1:6379> sadd names "aaa"#set集合中添加元素
(integer) 1
127.0.0.1:6379> sadd names "sb"
(integer) 1
127.0.0.1:6379> sadd names "ccc"
(integer) 1
127.0.0.1:6379> SMEMBERS names#查看指定set集合的所有值
1) "ccc"
2) "aaa"
3) "sb"
127.0.0.1:6379> SISMEMBER names aaa #判断是否是set元素
(integer) 1
127.0.0.1:6379> SISMEMBER names sss
(integer) 0
127.0.0.1:6379> SCARD names#获取set集合中的内容元素个数

###########################################################################
127.0.0.1:6379> srem names hhh#移除set集合中的指定元素

###########################################################################
set无序不重复集合

127.0.0.1:6379> SRANDMEMBER names#随机抽选出一个元素
"aaa"
127.0.0.1:6379> SRANDMEMBER names
"ccc"
127.0.0.1:6379> SRANDMEMBER names 2#随机抽选出指定个数的元素
1) "ccc"
2) "aaa"

###########################################################################
移除指定的key，随机删除一个key

127.0.0.1:6379> SMEMBERS names
1) "ccc"
2) "aaa"
3) "sb"
127.0.0.1:6379> SPOP names#随机移除元素
"ccc"
127.0.0.1:6379> SPOP names
"sb"

###########################################################################
将一个指定的值，移动到另外一个set集合中

127.0.0.1:6379> SMOVE names ages "aaa"#将一个指定的值，移动到另外一个集合
(integer) 1

###########################################################################
共同关注，交集，，，微博，b站，用户将所有的关注放在一个set集合中，粉丝也放在集合中共同关注，共同爱好，推荐好友
127.0.0.1:6379> SDIFF name1 name2#差集
1) "a"
2) "b"
127.0.0.1:6379> SINTER name1 name2#交集，共同好友
1) "c"
127.0.0.1:6379> SUNION name1 name2#并集
1) "c"
2) "e"
3) "a"
4) "b"
5) "d"


```

## 4.hash

**常用命令** ：hget/hset/hgetall等

**应用场景** ：我们要存储一个用户信息对象数据，其中包括用户ID、用户姓名、年龄和生日，通过用户ID我们希望获取该用户的姓名或者年龄或者生日；

-----------------------------------------------------------------------------------------------------------------------------------------------------------

map集合，key-map集合，本质和String类型没有太大区别，还是一个简单的key-value

```bash
127.0.0.1:6379> hset myhash name1 aaa#set一个具体的k-v
(integer) 1
127.0.0.1:6379> hget myhash name1#获取一个字段值
"aaa"
127.0.0.1:6379> hmset myhash name1 hello name2 world#set多个k-v
OK
127.0.0.1:6379> hmget myhash name1 name2#获取多个字段值
1) "hello"
2) "world"
127.0.0.1:6379> HGETALL myhash#获取全部数据
1) "name1"
2) "hello"
3) "name2"
4) "world"
127.0.0.1:6379> hdel myhash name1#删除hash指定的key字段，对应的value值也就无了
(integer) 1
127.0.0.1:6379> HGETALL myhash
1) "name2"
2) "world"

###########################################################################
hlen

127.0.0.1:6379> hlen myhash#获取hash表的字段数量
(integer) 1
127.0.0.1:6379> HMSET myhash name1 hello name2 world
OK
127.0.0.1:6379> HGETALL myhash
1) "name2"
2) "world"
3) "name1"
4) "hello"
127.0.0.1:6379> hlen myhash
(integer) 2
127.0.0.1:6379> HEXISTS myhash name3#判断hash中指定的字段是否存在
(integer) 0

###########################################################################
只获取所有的key或只获取所有的value
127.0.0.1:6379> HKEYS myhash#获取所有的字段
1) "name2"
2) "name1"
127.0.0.1:6379> HVALS myhash#获取所有的值
1) "world"
2) "hello"

###########################################################################
incr decr

127.0.0.1:6379> hset myhash name3 3#指定增量
(integer) 1
127.0.0.1:6379> HINCRBY myhash name3 1
(integer) 4
127.0.0.1:6379> HINCRBY myhash name3 -1
(integer) 3
127.0.0.1:6379> hsetnx myhash name4 hey#如果不存在可以设置
(integer) 1
127.0.0.1:6379> hsetnx myhash name4 key#如果存在不能设置
(integer) 0

hash的应用：变更的数据user name age，用户信息的保存，经常变动的信息，更适合存对象，string更适合字符串
```

## 5.Zset

**常用命令** ：zadd/zrange/zrem/zcard等；

**应用场景** ：Redis sorted set的使用场景与set类似，区别是set不是自动有序的，而sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择sorted set数据结构，比如twitter 的public timeline可以以发表时间作为score来存储，这样获取时就是自动按时间排好序的。

-----------------------------------------------------------------------------------------------------------------------------------------------------------

有序集合，在set的基础上增加了一个值，

```bash
127.0.0.1:6379> zadd myset 1 one#添加一个值
(integer) 1
127.0.0.1:6379> zadd myset 2 two 3 three#添加多个值
(integer) 2
127.0.0.1:6379> ZRANGE myset 0 -1
1) "one"
2) "two"
3) "three"

###########################################################################
排序

127.0.0.1:6379> zadd salary 3000 aaa#添加三个用户
(integer) 1
127.0.0.1:6379> zadd salary 100 aaa1
(integer) 1
127.0.0.1:6379> zadd salaazry 1001 aaa2
(integer) 1
127.0.0.1:6379> ZRANGEBYSCORE salary -inf +inf#显示全部用户，从小到大排序
1) "aaa1"
2) "aaa2"
3) "aaa"
127.0.0.1:6379> ZREVRANGE salary 0 -1#显示全部用户，从大到小排序
1) "aaa2"
2) "aaa1"
127.0.0.1:6379> ZRANGEBYSCORE salary -inf +inf withscores
1) "aaa1"
2) "100"
3) "aaa2"
4) "1001"
5) "aaa"
6) "3000"
127.0.0.1:6379> ZRANGEBYSCORE salary -inf 1002 withscores
1) "aaa1"
2) "100"
3) "aaa2"
4) "1001"

###########################################################################
移除rem中的元素
127.0.0.1:6379> zrange salary 0 -1
1) "aaa1"
2) "aaa2"
3) "aaa"
127.0.0.1:6379> zrem salary aaa #移除有序集合中的指定元素
(integer) 1
127.0.0.1:6379> zrange salary 0 -1
1) "aaa1"
2) "aaa2"
127.0.0.1:6379> zcard salary#获取有序集合中的元素数量
(integer) 2
###########################################################################
127.0.0.1:6379> zadd myset 1 hello
(integer) 1
127.0.0.1:6379> zadd myset 2 world 3 aaa
(integer) 2
127.0.0.1:6379> ZCOUNT myset 1 3#获取指定区间的成员数量
(integer) 3
127.0.0.1:6379> ZCOUNT myset 1 2
(integer) 2

```

# Redis的三大特殊数据类型

#### geospatial地理位置

朋友定位，附近的人，打车距离的计算 geo

```bash
###########################################################################
#规则:两级无法直接添加，一般会下载程序数据，直接java一次性导入
#参数 key 经度、纬度、名称，经纬度必须有效
#geoadd：将指定的地理空间位置（经度、纬度、名称）添加到指定的key中。
localhost:6379> GEOADD china:city 112.48699 37.94036  taiyuan
(integer) 1
localhost:6379> GEOADD china:city 121.48941 31.40527 shanghai
(integer) 1
localhost:6379> 

###########################################################################
获得当前定位，一定是一个坐标值
#GEOPOS：从key里返回所有给定位置元素的位置（经度和纬度）。
localhost:6379> GEOPOS china:city taiyuan shanghai
1) 1) "112.4869886040687561"
   2) "37.94035900368394465"
2) 1) "121.48941010236740112"
   2) "31.40526993848380499"


###########################################################################
GEODIST：返回两个给定位置之间的距离。
指定单位的参数 unit 必须是以下单位的其中一个：
m 表示单位为米。
km 表示单位为千米。
mi 表示单位为英里。
ft 表示单位为英尺。
localhost:6379> GEOADD china:city 120.21201 30.2084 hangzhou
(integer) 1
localhost:6379> GEODIST china:city hangzhou shanghai km
"180.5896"


###########################################################################
附近的人？获得附近所有人的地址，定位，通过半径来查询
GEORADIUS：以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素。
范围可以使用以下其中一个单位：
m 表示单位为米。
km 表示单位为千米。
mi 表示单位为英里。
ft 表示单位为英尺。
所有的数据都应该录入，才会让结果更加清晰，可用于周围人功能

localhost:6379> GEORADIUS china:city 120.21 30.20 200 km
1) "hangzhou"
2) "shanghai"

localhost:6379> GEORADIUS china:city 120.21 30.20 200 km withdist
1) 1) "hangzhou"
   2) "0.9540"
2) 1) "shanghai"
   2) "181.4122"
   
  localhost:6379> GEORADIUS china:city 120.21 30.20 200 km withcoord
1) 1) "hangzhou"
   2) 1) "120.21200805902481079"
      2) "30.20839995425554747"
2) 1) "shanghai"
   2) 1) "121.48941010236740112"
      2) "31.40526993848380499"
localhost:6379> GEORADIUS china:city 120.21 30.20 200 km withcoord withdist
1) 1) "hangzhou"
   2) "0.9540"
   3) 1) "120.21200805902481079"
      2) "30.20839995425554747"
2) 1) "shanghai"
   2) "181.4122"
   3) 1) "121.48941010236740112"
      2) "31.40526993848380499"
      
###########################################################################
GEORADIUSBYMEMBER：
这个命令和 GEORADIUS 命令一样， 都可以找出位于指定范围内的元素， 但是 GEORADIUSBYMEMBER 的中心点是由给定的位置元素决定的， 而不是像 GEORADIUS 那样， 使用输入的经度和纬度来决定中心点
指定成员的位置被用作查询的中心。可用于城市定位
localhost:6379> GEORADIUSBYMEMBER china:city hangzhou 200 km
1) "hangzhou"
2) "shanghai"
2) "taiyuan"
127.0.0.1:6379> GEORADIUSBYMEMBER china:city shanghai 400 km
1) "hangzhou"
2) "shanghai"

###########################################################################
GEOHASH：该命令将返回11个字符的Geohash字符串
#将二维经纬度转化为一维的字符串，两个字符串越接近距离越近
localhost:6379> GEOHASH china:city taiyuan
1) "wqxzzdyd8g0"
localhost:6379> GEOHASH china:city hangzhou
1) "wtm7z7r8wv0"

###########################################################################
查看地图中全部元素，移除指定元素
localhost:6379> ZRANGE china:city 0 -1
1) "taiyuan"
2) "hangzhou"
3) "shanghai"
localhost:6379> zrem china:city hangzhou
(integer) 1
127.0.0.1:6379> ZRANGE china:city 0 -1
1) "taiyuan"
2) "shanghai"
geo底层就是zset

```

#### Hyperloglog

基数统计，存在误差
根据输入键值，返回基数（键值中数据的不同数，一个范围，不准确），不会保存输入元素

```bash
127.0.0.1:6379> PFADD mykey a b c d e f g 
(integer) 1
127.0.0.1:6379> PFCOUNT mykey
(integer) 7
127.0.0.1:6379> PFADD mykey2 a b c d s rf we x f 
(integer) 1
127.0.0.1:6379> PFCOUNT mykey2
(integer) 9
127.0.0.1:6379> PFMERGE mykey3 mykey mykey2
OK
127.0.0.1:6379> PFCOUNT mykey3
(integer) 11

```

#### Bitmaps

位存储

0 1 0 1 

统计用户信息，活跃，不活跃！登录，未登录！打卡，全年打卡！两个状态的都可以用Bitmaps

Bitmaps：位图，数据结构！都是操作二进制位来进行记录，就只有0和1两个状态，省内存

```ba
127.0.0.1:6379> SETBIT sign 0 1
(integer) 0
127.0.0.1:6379> SETBIT sign 1 1
(integer) 0
127.0.0.1:6379> SETBIT sign 2 0
(integer) 0
127.0.0.1:6379> SETBIT sign 3 1
(integer) 0
127.0.0.1:6379> SETBIT sign 4 0
(integer) 0
127.0.0.1:6379> SETBIT sign 5 1
(integer) 0
127.0.0.1:6379> SETBIT sign 6 1

```

记录周一到周日的打卡

查看某一天是否打卡

```ba
127.0.0.1:6379> GETBIT sign 2
(integer) 0
127.0.0.1:6379> GETBIT sign 1
(integer) 1
```

统计打卡的天数

```ba
127.0.0.1:6379> BITCOUNT sign
(integer) 5
```

# redis实现乐观锁

悲观锁：很悲观，什么时候都会出问题，无论做什么都会加锁，很影响性能

乐观锁：

- 很乐观，认为什么时候都不会出问题，所以不会上锁！更新数据的时候去判断一下，再次期间，是否有人修改数据
- 获取version
- 更新的时候比较version



```ba
localhost:6379> watch money
OK
localhost:6379> multi
OK
localhost:6379> INCRBY money 10
QUEUED
localhost:6379> exec
(nil)
```

```ba
[root@Sunrise ~]# cd /usr/local
[root@Sunrise local]# cd redis/
[root@Sunrise redis]# cd src
[root@Sunrise src]# ./redis-cli 
127.0.0.1:6379> get money
"20"
127.0.0.1:6379> INCRBY money 10
(integer) 30
127.0.0.1:6379> INCRBY money 10
(integer) 40
```

# SpringBoot整合redis

## 认识一下Jedis

​	[Jedis](https://link.jianshu.com?t=https://github.com/xetorthio/jedis)是Redis官方推荐的Java连接开发工具。要在Java开发中使用好Redis中间件，必须对Jedis熟悉才能写成漂亮的代码。

## 整合redis

1.导入依赖

```ba
 	<dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-redis</artifactId>
            <version>1.4.1.RELEASE</version>
        </dependency>
        <dependency>
            <groupId>com.alibaba</groupId>
            <artifactId>fastjson</artifactId>
            <version>1.2.62</version>
        </dependency>
```

添加yml

```ba
spring:
  redis:
    host: 127.0.0.1
    port: 6379
```





2.RedisTemplate类

```java
package cn.xinzhi.config;

import com.fasterxml.jackson.annotation.JsonAutoDetect;
import com.fasterxml.jackson.annotation.PropertyAccessor;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.RedisSerializer;
import org.springframework.data.redis.serializer.StringRedisSerializer;

import java.net.UnknownHostException;

@Configuration
public class RedisConfig {
    /**
     * @description 创建RedisTemplate 的操作类
     */
    @Bean
    @SuppressWarnings("all")
    public RedisTemplate<String, Object> redisTemplate1(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException {
        RedisTemplate<String, Object> template = new RedisTemplate<String, Object>();
        template.setConnectionFactory(redisConnectionFactory);

        // json序列化配置
        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
        ObjectMapper om = new ObjectMapper();
        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
        jackson2JsonRedisSerializer.setObjectMapper(om);

        // String 的序列化
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();

        // key采用String的序列化方式
        template.setKeySerializer(stringRedisSerializer);
        template.setHashKeySerializer(stringRedisSerializer); // hash
        template.setValueSerializer(jackson2JsonRedisSerializer); // value
        template.setHashValueSerializer(jackson2JsonRedisSerializer); // hash的value
        template.afterPropertiesSet();

        return template;
    }


    // 创建redis的key序列化规则
    private RedisSerializer<?> keySerializer() {
        return new StringRedisSerializer();
    }

    // 值使用jackson进行序列化
    private RedisSerializer<?> valueSerializer() {
        return new GenericJackson2JsonRedisSerializer();
        // return new JdkSerializationRedisSerializer();
    }

}

```



3.RedisUtil类

````java
package cn.xinzhi.util;
import java.util.Collection;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.TimeUnit;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.stereotype.Component;
import org.springframework.util.CollectionUtils;
/**
 * Redis工具类
 * @author ZENG.XIAO.YAN
 * @date   2018年6月7日
 */
@Component
public final class RedisUtil {
    @Autowired
    private RedisTemplate<String, Object> redisTemplate;
    // =============================common============================
    /**
     * 指定缓存失效时间
     * @param key 键
     * @param time 时间(秒)
     * @return
     */
    public boolean expire(String key, long time) {
        try {
            if (time > 0) {
                redisTemplate.expire(key, time, TimeUnit.SECONDS);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }
    /**
     * 根据key 获取过期时间
     * @param key 键 不能为null
     * @return 时间(秒) 返回0代表为永久有效
     */
    public long getExpire(String key) {
        return redisTemplate.getExpire(key, TimeUnit.SECONDS);
    }

    /**
     * 判断key是否存在
     * @param key 键
     * @return true 存在 false不存在
     */
    public boolean hasKey(String key) {
        try {
            return redisTemplate.hasKey(key);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 删除缓存
     * @param key 可以传一个值 或多个
     */
    @SuppressWarnings("unchecked")
    public void del(String... key) {
        if (key != null && key.length > 0) {
            if (key.length == 1) {
                redisTemplate.delete(key[0]);
            } else {
                redisTemplate.delete((Collection<String>) CollectionUtils.arrayToList(key));
            }
        }
    }
    // ============================String=============================
    /**
     * 普通缓存获取
     * @param key 键
     * @return 值
     */
    public Object get(String key) {
        return key == null ? null : redisTemplate.opsForValue().get(key);
    }

    /**
     * 普通缓存放入
     * @param key 键
     * @param value 值
     * @return true成功 false失败
     */
    public boolean set(String key, Object value) {
        try {
            redisTemplate.opsForValue().set(key, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 普通缓存放入并设置时间
     * @param key 键
     * @param value 值
     * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期
     * @return true成功 false 失败
     */
    public boolean set(String key, Object value, long time) {
        try {
            if (time > 0) {
                redisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS);
            } else {
                set(key, value);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }
    /**
     * 递增
     * @param key 键
     * @param delta 要增加几(大于0)
     * @return
     */
    public long incr(String key, long delta) {
        if (delta < 0) {
            throw new RuntimeException("递增因子必须大于0");
        }
        return redisTemplate.opsForValue().increment(key, delta);
    }

    /**
     * 递减
     * @param key 键
     * @param delta 要减少几(小于0)
     * @return
     */
    public long decr(String key, long delta) {
        if (delta < 0) {
            throw new RuntimeException("递减因子必须大于0");
        }
        return redisTemplate.opsForValue().increment(key, -delta);
    }

    // ================================hash  key - Map=================================
    /**
     * HashGet
     * @param key 键 不能为null
     * @param item 项 不能为null
     * @return 值
     */
    public Object hget(String key, String item) {
        return redisTemplate.opsForHash().get(key, item);
    }

    /**
     * 获取hashKey对应的所有键值
     * @param key 键
     * @return 对应的多个键值
     */
    public Map<Object, Object> hmget(String key) {
        return redisTemplate.opsForHash().entries(key);
    }

    /**
     * HashSet
     * @param key 键
     * @param map 对应多个键值
     * @return true 成功 false 失败
     */
    public boolean hmset(String key, Map<String, Object> map) {
        try {
            redisTemplate.opsForHash().putAll(key, map);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }
    /**
     * HashSet 并设置时间
     * @param key 键
     * @param map 对应多个键值
     * @param time 时间(秒)
     * @return true成功 false失败
     */
    public boolean hmset(String key, Map<String, Object> map, long time) {
        try {
            redisTemplate.opsForHash().putAll(key, map);
            if (time > 0) {
                expire(key, time);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 向一张hash表中放入数据,如果不存在将创建
     * @param key 键
     * @param item 项
     * @param value 值
     * @return true 成功 false失败
     */
    public boolean hset(String key, String item, Object value) {
        try {
            redisTemplate.opsForHash().put(key, item, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }
    /**
     * 向一张hash表中放入数据,如果不存在将创建
     * @param key 键
     * @param item 项
     * @param value 值
     * @param time 时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间
     * @return true 成功 false失败
     */
    public boolean hset(String key, String item, Object value, long time) {
        try {
            redisTemplate.opsForHash().put(key, item, value);
            if (time > 0) {
                expire(key, time);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 删除hash表中的值
     * @param key 键 不能为null
     * @param item 项 可以使多个 不能为null
     */

    public void hdel(String key, Object... item) {
        redisTemplate.opsForHash().delete(key, item);
    }

    /**
     * 判断hash表中是否有该项的值
     * @param key 键 不能为null
     * @param item 项 不能为null
     * @return true 存在 false不存在
     */
    public boolean hHasKey(String key, String item) {
        return redisTemplate.opsForHash().hasKey(key, item);
    }

    /**
     * hash递增 如果不存在,就会创建一个 并把新增后的值返回
     * @param key 键
     * @param item 项
     * @param by 要增加几(大于0)
     * @return
     */
    public double hincr(String key, String item, double by) {
        return redisTemplate.opsForHash().increment(key, item, by);
    }
    /**
     * hash递减
     * @param key 键
     * @param item 项
     * @param by 要减少记(小于0)
     * @return
     */
    public double hdecr(String key, String item, double by) {
        return redisTemplate.opsForHash().increment(key, item, -by);
    }



    // ============================set=============================
    /**
     * 根据key获取Set中的所有值
     * @param key 键
     * @return
     */
    public Set<Object> sGet(String key) {
        try {
            return redisTemplate.opsForSet().members(key);
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
    }

    /**
     * 根据value从一个set中查询,是否存在
     * @param key 键
     * @param value 值
     * @return true 存在 false不存在
     */
    public boolean sHasKey(String key, Object value) {
        try {
            return redisTemplate.opsForSet().isMember(key, value);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }
    /**
     * 将数据放入set缓存
     * @param key 键
     * @param values 值 可以是多个
     * @return 成功个数
     */
    public long sSet(String key, Object... values) {
        try {
            return redisTemplate.opsForSet().add(key, values);
        } catch (Exception e) {
            e.printStackTrace();
            return 0;
        }
    }

    /**
     * 将set数据放入缓存
     * @param key 键
     * @param time 时间(秒)
     * @param values 值 可以是多个
     * @return 成功个数
     */
    public long sSetAndTime(String key, long time, Object... values) {
        try {
            Long count = redisTemplate.opsForSet().add(key, values);
            if (time > 0)
                expire(key, time);
            return count;
        } catch (Exception e) {
            e.printStackTrace();
            return 0;
        }
    }

    /**
     * 获取set缓存的长度
     * @param key 键
     * @return
     */
    public long sGetSetSize(String key) {
        try {
            return redisTemplate.opsForSet().size(key);
        } catch (Exception e) {
            e.printStackTrace();
            return 0;
        }
    }

    /**
     * 移除值为value的
     * @param key 键
     * @param values 值 可以是多个
     * @return 移除的个数
     */
    public long setRemove(String key, Object... values) {
        try {
            Long count = redisTemplate.opsForSet().remove(key, values);
            return count;
        } catch (Exception e) {
            e.printStackTrace();
            return 0;
        }
    }
    // ===============================list=================================
    /**
     * 获取list缓存的内容
     * @param key 键
     * @param start 开始
     * @param end 结束 0 到 -1代表所有值
     * @return
     */
    public List<Object> lGet(String key, long start, long end) {
        try {
            return redisTemplate.opsForList().range(key, start, end);
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
    }

    /**
     * 获取list缓存的长度
     * @param key 键
     * @return
     */
    public long lGetListSize(String key) {
        try {
            return redisTemplate.opsForList().size(key);
        } catch (Exception e) {
            e.printStackTrace();
            return 0;
        }
    }
    /**
     * 通过索引 获取list中的值
     * @param key 键
     * @param index 索引 index>=0时， 0 表头，1 第二个元素，依次类推；index<0时，-1，表尾，-2倒数第二个元素，依次类推
     * @return
     */
    public Object lGetIndex(String key, long index) {
        try {
            return redisTemplate.opsForList().index(key, index);
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
    }

    /**
     * 将list放入缓存
     * @param key 键
     * @param value 值
     * @param
     * @return
     */
    public boolean lSet(String key, Object value) {
        try {
            redisTemplate.opsForList().rightPush(key, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 将list放入缓存
     * @param key 键
     * @param value 值
     * @param time 时间(秒)
     * @return
     */
    public boolean lSet(String key, Object value, long time) {
        try {
            redisTemplate.opsForList().rightPush(key, value);
            if (time > 0)
                expire(key, time);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 将list放入缓存
     * @param key 键
     * @param value 值
     * @return
     */
    public boolean lSet(String key, List<Object> value) {
        try {
            redisTemplate.opsForList().rightPushAll(key, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 将list放入缓存
     *
     * @param key 键
     * @param value 值
     * @param time 时间(秒)
     * @return
     */
    public boolean lSet(String key, List<Object> value, long time) {
        try {
            redisTemplate.opsForList().rightPushAll(key, value);
            if (time > 0)
                expire(key, time);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 根据索引修改list中的某条数据
     * @param key 键
     * @param index 索引
     * @param value 值
     * @return
     */
    public boolean lUpdateIndex(String key, long index, Object value) {
        try {

            redisTemplate.opsForList().set(key, index, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }
    /**
     * 移除N个值为value
     * @param key 键
     * @param count 移除多少个
     * @param value 值
     * @return 移除的个数
     */
    public long lRemove(String key, long count, Object value) {
        try {
            Long remove = redisTemplate.opsForList().remove(key, count, value);
            return remove;
        } catch (Exception e) {
            e.printStackTrace();
            return 0;
        }
    }
}
````

## Redis缓存热点数据小案例

导入依赖

```jav
<dependencies>
        <dependency>
            <groupId>com.alibaba</groupId>
            <artifactId>druid</artifactId>
            <version>1.2.1</version>
        </dependency>


        <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-jdbc</artifactId>
        </dependency>

        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-thymeleaf</artifactId>
        </dependency>
        <!--集成redis-->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-redis</artifactId>
            <version>1.4.1.RELEASE</version>
        </dependency>
        <dependency>
            <groupId>com.alibaba</groupId>
            <artifactId>fastjson</artifactId>
            <version>1.2.62</version>
        </dependency>
        

        <!--        集成redis结束-->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-devtools</artifactId>
            <scope>runtime</scope>
            <optional>true</optional>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-configuration-processor</artifactId>
            <optional>true</optional>
        </dependency>
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.mybatis.spring.boot</groupId>
            <artifactId>mybatis-spring-boot-starter</artifactId>
            <version>2.0.1</version>
        </dependency>
    </dependencies>
    
    
    
    
    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
                <configuration>
                    <excludes>
                        <exclude>
                            <groupId>org.projectlombok</groupId>
                            <artifactId>lombok</artifactId>
                        </exclude>
                    </excludes>
                </configuration>
            </plugin>
        </plugins>

            <resources>
                <resource>
                    <directory>src/main/java</directory>
                    <includes>
                        <include>**/*.properties</include>
                        <include>**/*.xml</include>
                    </includes>
                    <filtering>false</filtering>
                </resource>
                <resource>
                    <directory>src/main/resources</directory>
                    <includes>
                        <include>**/*.*</include>
                    </includes>
                    <filtering>false</filtering>
                </resource>
            </resources>

    </build>
```



配置yml文件

```java
spring:
  redis:
    host: 127.0.0.1
    port: 6379
#    生菜   Lettuce是一个高性能基于Java编写的Redis驱动框架
    lettuce:
      pool:
#        最大等待数
        max-wait: 0
#        最大空闲
        max-idle: 0
#        最小空闲
        min-idle: 0
#        最大连接数
        max-active: 0
#        连接超时
    timeout: 30000
#    数据源
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://localhost:3306/book?serverTimezone=GMT%2B8&useSSL=true
    username: root
    password: xiaozeng
#    德鲁伊 数据库连接池
    type: com.alibaba.druid.pool.DruidDataSource
  thymeleaf:
    cache: false

#mybatis的相关配置
mybatis:
  #mapper配置文件
  mapper-locations: classpath:mybatisMapper/*.xml
  type-aliases-package: cn.xinzhi.pojo




```



定义dao层接口

```java
package cn.xinzhi.dao;

import cn.xinzhi.pojo.Info;
import org.apache.ibatis.annotations.Mapper;
import org.apache.ibatis.annotations.Param;
import org.springframework.stereotype.Repository;

@Mapper
@Repository
public interface Iinfo {
    /**
     * 查询所有
     * @return
     */
    Info queryInfoByid(@Param("id") Integer id);


}

```

xml文件

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
        "https://www.mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="cn.xinzhi.dao.Iinfo">
    <!-- 查找预约记录列表 -->
    <select id="queryInfoByid" resultType="Info">
        select id,title,author,info,date,votes,views from article where id = #{id}
    </select>
</mapper>
```



实体类

```java
package cn.xinzhi.pojo;

public class Info {
    private Integer id;
    private String title;
    private String author;
    private String info;
    private String date;
    //点赞数
    private Integer votes;
    //浏览量
    private Integer views;

    public Integer getVotes() {
        return votes;
    }

    public void setVotes(Integer votes) {
        this.votes = votes;
    }

    public Integer getViews() {
        return views;
    }

    public void setViews(Integer views) {
        this.views = views;
    }

    public Integer getId() {
        return id;
    }

    public void setId(Integer id) {
        this.id = id;
    }

    public String getTitle() {
        return title;
    }

    public void setTitle(String title) {
        this.title = title;
    }

    public String getAuthor() {
        return author;
    }

    public void setAuthor(String author) {
        this.author = author;
    }

    public String getInfo() {
        return info;
    }

    public void setInfo(String info) {
        this.info = info;
    }

    public String getDate() {
        return date;
    }

    public void setDate(String date) {
        this.date = date;
    }
}

```

service层接口

```java
package cn.xinzhi.service;

import cn.xinzhi.pojo.Info;


public interface IinfoService {

    Info queryInfoByid (Integer id);


}

```

实现类

```jav
package cn.xinzhi.service.impl;

import cn.xinzhi.dao.Iinfo;
import cn.xinzhi.pojo.Info;
import cn.xinzhi.service.IinfoService;
import cn.xinzhi.until.RedisUtil;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

@Service
public class IinfoServiceImpl  implements IinfoService {
    @Autowired
    private Iinfo iinfo;

    public void setIinfo(Iinfo iinfo) {
        this.iinfo = iinfo;
    }
    @Autowired
    private RedisUtil redisUtil;

    public void setRedisUtil(RedisUtil redisUtil) {
        this.redisUtil = redisUtil;
    }

    @Override
    public Info queryInfoByid(Integer id) {
        String articleid = "article"+id;
        //缓存层查询
        Info article =(Info) redisUtil.hget("article", articleid);
        if (article == null){
            synchronized (this){
                    //持久层查询 放入缓存层
                Info info = iinfo.queryInfoByid(id);
                redisUtil.hset("article", articleid,info );
                System.out.println("持久层查询");
                return info;
            }
        }
        System.out.println("缓存层查询");
        return article;
    }
}

```

测试成功！

![1623312418579](Redis_index.assets/1623312418579.png)

阅读量和点赞数

service 层

```java
package cn.xinzhi.service;

import cn.xinzhi.pojo.Info;
import org.apache.ibatis.annotations.Param;


public interface IinfoService {
//通过id查询文章
    Info queryInfoByid (Integer id);

//通过id增加点赞数
    boolean addVotesByid(Integer id);
//通过阅id增加阅读量
    Integer addViewsByid(Integer id);


}

```

实现类

```java
@Override
    public boolean addVotesByid(Integer id) {
        String articleid = "article"+id;
        Info article1 = (Info)redisUtil.hget("article", articleid);
        article1.setVotes(article1.getVotes()+1);
        boolean article = redisUtil.hset("article", articleid, article1);
        return article;
    }

    @Override
    public Integer addViewsByid(Integer id) {
        String articleid = "article"+id;
        Info article1 = (Info)redisUtil.hget("article", articleid);
        article1.setViews(article1.getViews()+1);
        boolean article = redisUtil.hset("article", articleid, article1);
        return article1.getViews();
    }
```

controller

```java

    @RequestMapping("/add/{id}")
    public  String addArticleVotes(@PathVariable Integer id){
        return JSON.toJSONString(iinfoService.addVotesByid(id));
    }
    @RequestMapping("/addViews/{id}")
    public  String addArticleViews(@PathVariable Integer id){
        return JSON.toJSONString(iinfoService.addViewsByid(id));
    }
```



# Redis发布订阅（简介）

通信 队列 消息通信模式  关注系统

1.消息发送者 

2.频道

3.消息订阅者

下表列出了 redis 发布订阅常用命令：

| 序号 |                          命令及描述                          |
| :--- | :----------------------------------------------------------: |
| 1    | [PSUBSCRIBE pattern [pattern ...\]]订阅一个或多个符合给定模式的频道。 |
| 2    | [PUBSUB subcommand [argument [argument ...\]]](https://www.runoob.com/redis/pub-sub-pubsub.html) 查看订阅与发布系统状态。 |
| 3    | [PUBLISH channel message](https://www.runoob.com/redis/pub-sub-publish.html) 将信息发送到指定的频道。 |
| 4    | [PUNSUBSCRIBE [pattern [pattern ...\]]](https://www.runoob.com/redis/pub-sub-punsubscribe.html) 退订所有给定模式的频道。 |
| 5    | [SUBSCRIBE channel [channel ...\]](https://www.runoob.com/redis/pub-sub-subscribe.html) 订阅给定的一个或多个频道的信息。 |
| 6    | [UNSUBSCRIBE [channel [channel ...\]]](https://www.runoob.com/redis/pub-sub-unsubscribe.html) 指退订给定的频道。 |

消息订阅  ：

```bash
127.0.0.1:6379> SUBSCRIBE test
Reading messages... (press Ctrl-C to quit)
1) "subscribe"
2) "test"
3) (integer) 1
```

消息发送：

```bas
127.0.0.1:6379> PUBLISH test nihao
(integer) 2
127.0.0.1:6379>
```



# 补上昨天：Java序列化和反序列化的概念

一、序列化与反序列化
序列化：指堆内存中的java对象数据，通过某种方式把对存储到磁盘文件中，或者传递给其他网络节点（网络传输）。这个过程称为序列化，通常是指将数据结构或对象转化成二进制的过程。

即将对象转化为二进制，用于保存，或者网络传输。
反序列化：把磁盘文件中的对象数据或者把网络节点上的对象数据，恢复成Java对象模型的过程。也就是将在序列化过程中所生成的二进制串转换成数据结构或者对象的过程

与序列化相反，将二进制转化成对象。



**为什么实现Serializable可以完成序列化？**




# Redis配置文件简介

一、解析配置文件 redis.conf 
1、位置

![img](https://img-blog.csdn.net/20180807094443264?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMwNjA0OTg5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### 2、Units单位

![img](https://img-blog.csdn.net/20180807094932152?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMwNjA0OTg5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

1）配置大小单位，开头配置了一些基本的度量单位，只支持bytes，不支持bit

2）对大小写不敏感

3、**INCLUDES包含**

![img](https://img-blog.csdn.net/20180807095109665?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMwNjA0OTg5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

导入

可以通过includes包含，redis.conf 可以作为总闸，包含其他

4、GENERAL通用

1）Daemonize：设置为守护线程

2）Pidfile：进程管道id文件，如果没有指定其他路径，就用默认路径指定pid

3）Port：端口

6）Bind：127.0.0.1

7）Tcp-keepalive：单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置成60 

8）Loglevel：日志级别

9）Logfile：日志文件名

10）Syslog-enabled：是否把日志输出到syslog中

11）Syslog-ident：指定syslog里的日志标志

12）Syslog-facility：指定syslog设备，可以是USER或LOCAL0 - LOCAL7

13）Databases：数据库，默认情况下有16个库

5、SNAPSHOTTING快照

1）Save：

① save秒钟 写操作次数

![img](https://img-blog.csdn.net/20180807165438396?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMwNjA0OTg5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

RDB是整个内存的压缩过的Snapshot，RDB数据结构，可以配置复合的快照出发条件
② 禁用

![img](https://img-blog.csdn.net/20180807165616963?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMwNjA0OTg5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

如果想禁用RDB持久化的策略，只要不设置任何save命令，或者给save传入一个空字符串参数也可以。

5）dbfilename

6）dir

6、REPLICATION复制

7、SECURITY安全

访问密码的查看、设置和取消

![img](https://img-blog.csdn.net/20180807101758415?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMwNjA0OTg5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

8、LIMITS限制

1）Maxclients

设置Redis同时可以和多少个客户端进行连接。默认情况下为10000个客户端。当你无法设置进程文件句柄限制时，redis会设置为当前的文件句柄减去32，因为，redis会为自身内部处理逻辑留一些句柄出来。如果达到了此限制，redis会拒绝新的连接请求，并且向这些连接请求方发出 “max number of clients reached” 以作回应。

2）Maxmemory

设置Redis可以使用的内存量。一旦达到内存使用上限，redis会试图移除内部数据，移除规则可以通过maxmemory-policy来指定。如果redis无法根据移除规则来移除内存中的数据，或者设置了 “不允许移除”，那么Redis则会针对那些需要申请内存的指令返回错误信息，比如SET、LPUSH等。

但是对于无内存申请的指令，仍然会正常响应，比如GET等。如果你的Redis是主Redis（说明你的redis有从redis），那么在设置内存使用上限的时候，需要在系统中留出一些内存空间给同步队列缓存，只有在你设置的是 “不移除”的情况下，才不用考虑这个因素。

3）Maxmemory-policy：

### 缓存失效策略 淘汰策略

noeviction: 不删除策略, 达到最大内存限制时, 如果需要更多内存, 直接返回错误信息。 大多数写命令都会导致占用更多的内存(有极少数会例外, 如 DEL )。

allkeys-lru: 所有key通用; 优先删除最近最少使用(less recently used ,LRU) 的 key。

volatile-lru: 只限于设置了 expire 的部分; 优先删除最近最少使用(less recently used ,LRU) 的 key。

allkeys-random: 所有key通用; 随机删除一部分 key。

volatile-random: 只限于设置了 expire 的部分; 随机删除一部分 key。

volatile-ttl: 只限于设置了 expire 的部分; 优先删除剩余时间(time to live,TTL) 短的key。



# Redis持久化

redis是内存数据库，如果不将内存中的数据库状态保存到磁盘，那么一旦服务器进程退出，服务器中的数据库状态也会消失，所以redis提供了持久化功能

redis 本地持久化到硬盘有两种方式,一是快照(snapshotting),二是只追加文件(append-only file AOF)

**快照**

快照，顾名思义可以理解为拍照一样，把整个内存数据映射到硬盘中，保存一份到硬盘，因此恢复数据起来比较快，把数据映射回去即可，不像AOF，一条条的执行操作命令。

#### RDB(Redis DataBase)

RDB持久化是把当前进程数据生成快照保存到硬盘的过程，触发RDB持久化过程分为手动触发和自动触发

#### 1）触发机制

手动触发分别对应save和bgsave命令

**·save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存 比较大的实例会造成长时间阻塞，线上环境不建议使用**

fork ： 创建进程

**·bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子 进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短**

#### 2）自动触发RDB的持久

RDB文件的处理

保存：RDB文件保存在dir配置指定的目录下，文件名通过dbfilename配 置指定。可以通过执行config set dir{newDir}和config set dbfilename{newFileName}运行期动态执行，当下次运行时RDB文件会保存到新目录。

rdb保存的文件时dump.rdb都是在配置文件中配置的

测试：只要60s内修改了5次key，就会触发rdb操作

**触发机制：**

1.满足规则，自动触发

2.退出redis也会产生rdb文件

**恢复rdb文件：**

1.只需要将rdb文件放到redis启动目录即可redis启动的时候会自动检查dump.rdb回复其中的数据

2.查看位置

```bash
config get dir#如果该目录不存在这个dump.rdb文件，启动时就会自动恢复其中的数据
```

**RDB的优点：** 

1.RDB是一个紧凑压缩的二进制文件，代表Redis在某个时间点上的数据 快照。**非常适用于备份，全量复制等场景**。

2.Redis加载RDB恢复数据远远快于AOF的方式。

**RDB的缺点：**

1.RDB方式数据没办法做到实时持久化/秒级持久化。频繁执行成本过高。

2.RDB文件使用特定二进制格式保存，Redis版本演进过程中有多个格式 的RDB版本，存在老版本Redis服务无法兼容新版RDB格式的问题。

3.针对RDB不适合实时持久化的问题，Redis提供了AOF持久化方式来解决

**这个文件通常会备份**

#### AOF(Append Only File)

AOF（append only file）持久化：以独立日志的方式记录每次写命令， 重启时再重新执行AOF文件中的命令达到恢复数据的目的。AOF的**主要作用** 是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式。一句话将我们所有的命令都记录下来。history，恢复的时候就把这个文件全部执行一遍



aof保存的文件是：appendonly.aof文件

#### 优点：

1.每一次修改都同步，文件完整性更好

2.每秒同步一次可能会丢失一秒的数据

#### 缺点：

1.相对于数据文件来说，aof远远大于rdb，修复的速度比rdb慢

2.Aof是读写操作，运行效率慢，所以redis默认的配置就是rdb持久化

# Redis主从复制

集群：单机服务器处理到达瓶颈的时候，你就把单机复制几份，这样就构成了一个“集群”。集群中每台服务器就叫做这个集群的一个“节点”，所有节点构成了一个集群。

## 1.概述：

​	Master节点在平时提供服务，另外一个或多个Slave节点在平时不提供服务（或只提供数据读取服务）。当Master节点由于某些原因停止服务后，再人工/自动完成Slave节点到Master节点的切换工作，以便整个Redis集群继续向外提供服务。	将一台redis数据，复制到其他服务器

​	Redis主从复制优点：

​			主从复制，读写分离，负载均衡， 百分之八十是读 减缓服务器压力 

## 2.主从复制工作过程:

Redis的主从复制功能除了支持一个Master节点对应多个Slave节点的同时进行复制外，还支持Slave节点向其它多个Slave节点进行复制。这样使得我们能够灵活组织业务缓存数据的传播，例如使用多个Slave作为数据读取服务的同时，专门使用一个Slave节点为流式分析工具服务。Redis的主从复制功能分为两种数据同步模式进行：全量数据同步和增量数据同步。

**全量数据同步：**

先执行一次全同步 — 请求master BgSave出自己的一个RDB Snapshot文件发给slave，slave接收完毕后，清除掉自己的旧数据，然后将RDB载入内存。
![img](Redis_index.assets/20190603123330541.png)

**增量数据同步：**
再进行增量同步 — master作为一个普通的client连入slave，将所有写操作转发给slave，没有特殊的同步协议。

![img](Redis_index.assets/201906031234151.png)

## 1、主库master配置：

Master服务器不需要针对主从复制做任何的设置（这不包括对主从复制过程的配置优化）。

## 2、从库slave配置：

Slave节点上我们只需要做一件事情，就是打开slaveof选项：

slaveof选项的设置，给定master节点的ip和port就可以了

#192.168.61.140就是master节点

slaveof 192.168.10.10 6379

接着，我们马上就可以看看同步效果了。首先确保您的master节点使工作正常的，然后就可以启动Slave节点了

## 单机多redis

测试：

一主二从

修改四个：

​		端口

​		log

​		pid

​		rdb

启动三个redis集群

![1623226525755](Redis_index.assets/1623226525755.png)

info replication 查看主从信息

方式1：修改配置文件，slaveof 启动时，服务器读取配置文件，并自动成为指定服务器的从服务器，从而构成主从复制的关系

1. slaveof no one，将一台slave服务器提升为Master （提升某slave为master）
2. slaveof 192.168.184.135 6379（将slave挂至新的master上）

主机宕机

![1623227772323](Redis_index.assets/1623227772323.png)

从机没有老大

![1623227785106](Redis_index.assets/1623227785106.png)

这个时候就要手动配置老大

![1623228104139](Redis_index.assets/1623228104139.png)

重新认老大

![1623228167920](Redis_index.assets/1623228167920.png)

这种事是不是很麻烦？

# 哨兵模式（面试高频）

​	在主从模式的Redis系统中，从数据库在整个系统中起到了数据 冗余备份和 读写分离的作用，但是当数据库遇到异常中断服务后，我们只能通过手动的方式选择一个从数据库来升格为主数据库，显然这种方式很麻烦需要人工介入，这时通过哨兵模式可以实现自动化的系统监控和故障恢复。

## 1.什么是哨兵以及作用

  哨兵的作用是监控Redis系统的运行状态，功能包括以下两个:

| 序号 | 功能                                                   |
| ---- | ------------------------------------------------------ |
| 1    | 监控主数据库和从数据库是否正常运行                     |
| 2    | 主数据库出现故障时自动将从数据库转换为主数据库（选举） |

哨兵是一个独立的进程，使用哨兵的典型结构图如下:

![img](Redis_index.assets/20190317205956417.png)

在一主多从的Redis系统中，可以使用多个哨兵进行监控任务以保证系统的问题。

![在这里插入图片描述](Redis_index.assets/20190317210810156.png)

### 2.哨兵模式配置

修改src目录下的sentinel.conf文件.

![在这里插入图片描述](Redis_index.assets/20190317212249352.png)

哨兵模式只需要配置其监控的主数据库即可，哨兵会自动发现所有复制该数据库的从数据库。

![在这里插入图片描述](Redis_index.assets/20190317212343646.png)

```ba
sentinel monitor mymaster 127.0.0.1 6380 1
# sentinel monitor master-name ip redis-port quorum
```

| 命令        | 用例      | 说明                                                         |
| ----------- | --------- | ------------------------------------------------------------ |
| master-name | mymaster  | 要监控的主数据库的名称，可以自定义， 组成大小写字母，数字和". - _"组成 |
| ip          | 127.0.0.1 | 主数据库(master)的地址                                       |
| redis-port  | 6379      | 主数据库的端口                                               |
| quorum      | 1         | 最低通过的票数（主观下线）                                   |

启动哨兵

![1623230578387](Redis_index.assets/1623230578387.png)

结束主机试一下

6379变成主机

![1623230809628](Redis_index.assets/1623230809628.png)



![1623231071830](Redis_index.assets/1623231071830.png)

我们发现，主机再次上来他也能只当从机

3.一个哨兵监控多个Redis主从系统
配置

```ba
sentinel monitor mymaster 127.0.0.1 6380 2
sentinel monitor othermaster 192.168.88.60 6380 4
```


监控不同数据库使用不同的配置参数:

```ba
sentinel down-after-millisenconds mymaster 60000
sentinel down-after-millisenconds othermaster 10000
```

## 哨兵实现原理

哨兵启动后会与要监控的主数据库建立两条连接

![在这里插入图片描述](Redis_index.assets/20190317214429730.png)

 和主数据库连接建立完成后，哨兵会使用连接2发送如下命令:

1. 每10秒钟哨兵会向主数据库发送INFO 命令

2. 每2秒钟哨兵会向主数据库和从数据的_sentinel_:hello频道发送自己的消息。

3. 每1秒钟哨兵会向主数据、从数据库和其他哨兵节点发送PING命令。

   

   ​	首先,发送INFO命令会返回当前数据库的相关信息(运行id，从数据库信息等)从而实现新节点的自动发现，前面提到的配置哨兵时只需要监控Redis主数据库即可，因为哨兵可以借助INFO命令来获取所有的从数据库信息(slave),进而和这两个从数据库分别建立两个连接。在此之后哨兵会每个10秒钟向已知的主从数据库发送INFO命令来获取信息更新并进行相应的操作。
     接下来哨兵向主从数据库的_sentinel_:hello 频道发送信息来与同样监控该数据库的哨兵分享自己的信息。发送信息内容为:

```ba
<哨兵的地址>，<哨兵的端口>，<哨兵的运行ID>，<哨兵的配置版本>，
<主数据库的名字>，<主数据库的地址>，<主数据库的端口>，<主数据库的配置版本>
```

![在这里插入图片描述](Redis_index.assets/20190317220226562.png)

​	哨兵通过监听的_sentinel_:hello频道接收到其他哨兵发送的消息后会判断哨兵是不是新发现的哨兵，如果是则将其加入已发现的哨兵列表中并创建一个到其的连接(哨兵与哨兵只会创建用来发送PING命令的连接，不会创建订阅频道的连接)。

​	实现了自定发现从数据库和其他哨兵节点后，哨兵要做的就是定时监控这些数据和节点运行情况，每隔一定时间向这些节点发送PING命令来监控。间隔时间和down-after-milliseconds选项有关，down-after-milliseconds的值小于1秒时，哨兵会每隔down-after-milliseconds指定的时间发送一次PING命令，当down-after-milliseconds的值大于1秒时，哨兵会每隔1秒发送一次PING命令。例如:

```ba
// 每隔1秒发送一次PING命令
sentinel down-after-milliseconds mymaster 60000
// 每隔600毫秒发送一次PING命令
sentinel down-after-milliseconds othermaster 600
```

### 主观下线

  当超过down-after-milliseconds指定时间后，如果被PING的数据库或节点仍然未回复，则哨兵认为其主观下线(subjectively down),主观下线表示从当前的哨兵进程看来，该节点已经下线。

### 客观下线

  在主观下线后，如果该节点是主数据库，则哨兵会进一步判断是否需要对其进行故障恢复，哨兵发送SENTINEL is-master-down-by-addr 命令询问其他哨兵节点以了解他们是否也认为该主数据库主观下线，如果达到指定数量时，哨兵会认为其客观下线(objectively down),并选举领头的哨兵节点对主从系统发起故障恢复。这个指定数量就是前面配置的 quorum参数。

```ba
sentinel monitor mymaster 127.0.0.1 6380 2
```

### 选举领头哨兵

  当前哨兵虽然发现了主数据客观下线，需要故障恢复，但故障恢复需要由领头哨兵来完成。这样来保证同一时间只有一个哨兵来执行故障恢复，选举领头哨兵的过程使用了Raft算法，具体过程如下:

1.发现主数据库客观下线的哨兵节点(A)向每个哨兵节点发送命令，要求对方选择自己成为领头哨兵

2.如果目标哨兵节点没有选过其他人，则会同样将A设置为领头哨兵
3.如果A发现有超过半数且超过quorum参数值的哨兵节点同样选择自己成为领头哨兵，则A成功成为领头哨兵
4.当有多个哨兵节点同时参选领头哨兵，则会出现没有任何节点当选的可能，此时每个参选节点将等待一个随机时间重新发起参选请求进行下一轮选举，直到选举成功。

### 故障恢复

 1.选出领头哨兵后，领头哨兵将会开始对主数据库进行故障恢复。步骤如下

首先领头哨兵将从停止服务的主数据库的从数据库中挑选一个来充当新的主数据库。

| 序号 | 挑选依据                                                     |
| ---- | ------------------------------------------------------------ |
| 1    | 所有在线的从数据库中，选择优先级最高的从数据库。优先级通过replica-priority参数设置 |
| 2    | 优先级相同，则复制的命令偏移量越大(复制越完整)越优先         |
| 3    | 如果以上都一样，则选择运行ID较小的从数据库                   |

### 服务器运行ID(runid)

- 概念:服务器运行ID是每一台服务器每次运行的身份识别码,一台服务器多次运行可以生成多个运行id
- 组成:运行id由40位字符组成,是一个随机的十六进制字符,例如:7cfbf53e4901277d7247db9fac7945af44dcc666

​	2.选出一个从数据库后，领头哨兵将向从数据库发送SLAVEOF NO ONE命令使其升格为主数据库，而后领头哨兵向其他从数据库发送 SLAVEOF命令来使其成为新主数据库的从数据库，最后一步则是更新内部的记录，将已经停止服务的旧的主数据库更新为新的主数据库的从数据库，使得当其恢复服务时自动以从数据库的身份继续服务


# redis的缓存击穿、穿透和雪崩

#### 缓存穿透(查不到)

缓存穿透是指查询一个根本不存在的数据，缓存层和持久层都不会命中。在日常工作中出于容错的考虑，如果从持久层查不到数据则不写入缓存层，缓存穿透将导致不存在的数据每次请求都要到持久层去查询。

演示

解决方案：

1. 缓存空对象
   - 缓存空对象：是指在持久层没有命中的情况下，对key进行set （key,null）

- 缓存空对象会有两个问题：第一，value为null 不代表不占用内存空间，空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间，比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。第二，缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为5分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象

2. 布隆过滤器拦截
   - 在访问缓存层和存储层之前，将存在的key用布隆过滤器提前保存起来，做第一层拦截，当收到一个对key请求时先用布隆过滤器验证是key否存在，如果存在在进入缓存层、存储层。可以使用bitmap做布隆过滤器。这种方法适用于数据命中不高、数据相对固定、实时性低的应用场景，代码维护较为复杂，但是缓存空间占用少。
   - 布隆过滤器实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。

★**布隆过滤器**

布隆过滤器，英文叫BloomFilter，可以说是一个二进制向量和一系列随机映射函数实现。 可以用于检索一个元素是否在一个集合中。

布隆过滤器：一种数据结构，是由一串很长的二进制向量组成，可以将其看成一个二进制数组。既然是二进制，那么里面存放的不是0，就是1，但是初始默认值都是0。

详解：https://blog.csdn.net/wuzhiwei549/article/details/106714765?spm=1001.2014.3001.5506

安装：

```bash
# 默认redis已经安装好了 文章redis是安装在/usr/local/redis下的
# 进入到redis目录
cd /usr/local/redis
# 创建module文件夹
mkdir module && cd module
# 如果没有安装git 可以安装一下git
yum -y install git
# 下载并且解压
wget https://github.com/RedisLabsModules/rebloom/archive/v1.1.1.tar.gz
tar -zxvf v1.1.1.tar.gz 
#成功后可看到目录下有个.so文件
cd RedisBloom-1.1.1
make
# 编译后会得到一个redisbloom.so的文件 然后在redis.conf增加如下配置
loadmodule ../module/RedisBloom-1.1.1/rebloom.so
# 重启redis
pkill redis
/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf
```

2.3 布隆过滤器的基本命令

```bas
bf.reserve(key, error_rate, capacity)
● key 键
● error_rate 错误比例,该比例越小,则需要的空间越大
● capacity 容量,当实际容量超过这个数的时候,误判率会增加

bf.add(key, value)
● key 键
● value 值

bf.exists(key, value)
● key 键
● value 值
```




#### 缓存击穿(量太大，缓存过期！)

微博

系统中存在以下两个问题时需要引起注意：

- 当前key是一个热点key（例如一个秒杀活动），并发量非常大。
- 重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的SQL、多次IO、多个依赖等。

在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃。

**解决方案：**

**1. 分布式互斥锁**

   只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。

**2. 永不过期**

- 从缓存层面来看，确实没有设置过期时间，所以不会出现热点key过期后产生的问题，也就是“物理”不过期。
- 从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去更新缓

2种方案对比：

**分布式互斥锁**：这种方案思路比较简单，但是存在一定的隐患，如果在查询数据库 + 和 重建缓存（key失效后进行了大量的计算）时间过长，也可能会存在死锁和线程池阻塞的风险，高并发情景下吞吐量会大大降低！但是这种方法能够较好地降低后端存储负载，并在一致性上做得比较好。

“永远不过期”：这种方案由于没有设置真正的过期时间，实际上已经不存在热点key产生的一系列危害，但是会存在数据不一致的情况，同时代码复杂度会增大。

#### 缓存雪崩

### 什么是分布式？

不同的业务模块部署在不同的服务器上或者同一个业务模块分拆多个子业务，部署在不同的服务器上，解决高并发的问题，提供可扩展性以及高可用性，业务中使用分布式的场景主要有分布式存储以及分布式计算。分布式存储中可以将数据分片到多个节点上，不仅可以提高性能（可扩展性），同时也可以使用多个节点对同一份数据进行备份。

**雪崩问题**

分布式系统都存在这样一个问题，由于网络的不稳定性，决定了任何一个服务的可用性都不是 100% 的。当网络不稳定的时候，作为服务的提供者，自身可能会被拖死，导致服务调用者阻塞，最终可能引发雪崩连锁效应。

**缓存雪崩**

当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力，造成数据库后端故障，从而引起应用服务器雪崩。

双11：停掉一些服务，保证主要的服务可用(服务降级)

**雪崩效应产生的几种场景**

- 流量激增：比如异常流量、用户重试导致系统负载升高；
- 缓存刷新：假设A为client端，B为Server端，假设A系统请求都流向B系统，请求超出了B系统的承载能力，就会造成B系统崩溃；
- 程序有Bug：代码循环调用的逻辑问题，资源未释放引起的内存泄漏等问题；
- 硬件故障：比如宕机，机房断电，光纤被挖断等。
- 数据库严重瓶颈，比如：长事务、sql超时等。

#### 解决方案

1、避免缓存集中失效，不同的key设置不同的失效时间

2、增加互斥锁，控制数据库请求，重建缓存。

3、提高缓存的HA（高可用），如：redis集群。

# Redis管道

## 一、redis的管道

1. ### 使用管道技术的原因

  redis是一个客户端-服务器（CS）模型和请求/响应协议的TCP服务器，使用和http类似的请求响应协议。一个client可以通过一个socket连接发起多个请求命令。每个请求命令发出后client通常会阻塞并等待redis服务处理，redis处理完请求命令后会将结果通过响应报文返回给client。所以，如果一个业务逻辑中需要多次发送redis操作时，每一条命令在网络传输中的往返时延（计算机网络了解一下）会远远大于执行时间，这也是为什么说影响redis性能的最大难题是网络时延。
  而管道（pipeline）可以一次性发送多条命令并在执行完后一次性将结果返回，pipeline通过减少客户端与redis的通信次数来实现降低往返延时时间，而且Pipeline 实现的原理是队列，而队列的原理是时先进先出，这样就保证数据的顺序性。
  单个执行与管道执行对比图

  ![在这里插入图片描述](Redis_index.assets/20181225164228900.png)


2. ### Redis管道的特点

  redis自带的命令行是没有管道技术的，只存在于各个客户端语音中，因为管道作用主要是，客户端在远程操作redis时，减少发送多个命令造成的网络时延TTL。

  通过pipeline方式当有大批量的操作时候。我们可以节省很多原来浪费在网络延迟的时间。但是，需要注意到用pipeline方式打包命令发送，redis必须在处理完所有命令前先缓存起所有命令的处理结果。打包的命令越多，缓存消耗内存也越多。所以并是不是打包的命令越多越好。此外，pipeline期间将“独占”当前redis连接，此期间将不能进行非“管道”类型的其他操作，直到该pipeline关闭。

​	pipeline不是原子性的，中间可能会存在部分失败的情况，也就是说不能保证每条命令都能执行成功，如果中间有命令出现错误，redis不会中断执行，而是直接执行下一条命令，然后将所有命令的执行结果（执行成果或者执行失败）放到列表中统一返回，如果需要每条命令都执行成功，我们在批量执行过程中需要监控执行数量和返回的成功数量是否一致。

3. ### pipeline管道使用场景

  ​	Pipeline在某些场景下非常有用，比如有多个command需要被及时提交，而且他们对相应结果没有互相依赖，对结果响应也无需立即获得，那么pipeline就可以充当这种批处理的工具；

```java
 @Override
    public String test() throws IOException {
        long start = System.currentTimeMillis();
        for (int i = 0; i < 100000 ; i++) {
            redisUtil.set("redistest:" + "k" + i, "v" + i);
        }
        long end =  System.currentTimeMillis();
        return String.valueOf(System.currentTimeMillis()-start);
    }

    @Override
    public String pipelineTest() throws IOException {
        long start = System.currentTimeMillis();

        List<String> result = redisTemplate.executePipelined(new SessionCallback() {

            //执行流水线

            public Object execute(RedisOperations redisOperations) throws DataAccessException {
                //批量处理的内容
                for (int i = 0; i < 100000 ; i++) {
                        redisOperations.opsForValue().set("redistest:" + "k" + i, "v" + i);
                    }
                //注意这里一定要返回null，最终pipeline的执行结果，才会返回给最外层
                return null;
            }
        });
        long end =  System.currentTimeMillis();
        return String.valueOf(System.currentTimeMillis()-start);
    }
```

